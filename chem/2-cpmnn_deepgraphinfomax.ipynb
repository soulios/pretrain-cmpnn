{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import collections\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "from chemprop.parsing import parse_train_args, modify_train_args\n",
    "from chemprop.data.utils import get_task_names, get_data\n",
    "from chemprop.models import build_model\n",
    "\n",
    "import networkx as nx\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem.rdMolDescriptors import GetMorganFingerprintAsBitVect\n",
    "from torch.utils import data\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.data import Batch\n",
    "from itertools import repeat, product, chain\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from loader import MoleculeDataset, mol_to_graph_data_obj_simple\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn.inits import uniform\n",
    "from torch_geometric.nn import global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cycle_index(num, shift):\n",
    "    arr = torch.arange(num) + shift\n",
    "    arr[-shift:] = torch.arange(shift)\n",
    "    return arr\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        size = self.weight.size(0)\n",
    "        uniform(size, self.weight)\n",
    "\n",
    "    def forward(self, x, summary):\n",
    "        h = torch.matmul(summary, self.weight)\n",
    "        return torch.sum(x*h, dim = 1)\n",
    "\n",
    "class Infomax(nn.Module):\n",
    "    def __init__(self, gnn, discriminator):\n",
    "        super(Infomax, self).__init__()\n",
    "        self.gnn = gnn\n",
    "        self.discriminator = discriminator\n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "        self.pool = global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoleculeDataset(719764)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bruno\\anaconda3\\envs\\GVQA\\lib\\site-packages\\torch_geometric\\deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "dataset_file = 'd_new_smiles'\n",
    "num_layer = 5\n",
    "csize = 3\n",
    "\n",
    "l1 = num_layer - 1\n",
    "l2 = l1 + csize\n",
    "\n",
    "#dataset = MoleculeDataset(\"data/dataset/\" + dataset_file, dataset=dataset_file ,transform = ExtractSubstructureContextPair(num_layer, l1, l2))\n",
    "#set up dataset\n",
    "dataset = MoleculeDataset(\"data/dataset/\" + dataset_file, dataset=dataset_file)\n",
    "\n",
    "print(dataset)\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch implementation of pre-training of graph neural networks')\n",
    "parser.add_argument('--device', type=int, default=0,\n",
    "                    help='which gpu to use if any (default: 0)')\n",
    "parser.add_argument('--batch_size', type=int, default=256,\n",
    "                    help='input batch size for training (default: 256)')\n",
    "parser.add_argument('--epochs', type=int, default=100,\n",
    "                    help='number of epochs to train (default: 100)')\n",
    "parser.add_argument('--lr', type=float, default=0.001,\n",
    "                    help='learning rate (default: 0.001)')\n",
    "parser.add_argument('--decay', type=float, default=0,\n",
    "                    help='weight decay (default: 0)')\n",
    "parser.add_argument('--num_layer', type=int, default=5,\n",
    "                    help='number of GNN message passing layers (default: 5).')\n",
    "parser.add_argument('--emb_dim', type=int, default=300,\n",
    "                    help='embedding dimensions (default: 300)')\n",
    "parser.add_argument('--dropout_ratio', type=float, default=0,\n",
    "                    help='dropout ratio (default: 0)')\n",
    "parser.add_argument('--JK', type=str, default=\"last\",\n",
    "                    help='how the node features across layers are combined. last, sum, max or concat')\n",
    "parser.add_argument('--dataset', type=str, default = 'zinc_standard_agent', help='root directory of dataset. For now, only classification.')\n",
    "parser.add_argument('--output_model_file', type = str, default = '', help='filename to output the pre-trained model')\n",
    "parser.add_argument('--gnn_type', type=str, default=\"gin\")\n",
    "parser.add_argument('--seed', type=int, default=0, help = \"Seed for splitting dataset.\")\n",
    "parser.add_argument('--num_workers', type=int, default = 8, help='number of workers for dataset loading')\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "device = torch.device(\"cuda:\" + str(args.device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 543/7248 [00:00<00:01, 5376.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7248/7248 [00:01<00:00, 5675.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tasks = 7\n"
     ]
    }
   ],
   "source": [
    "#set up model\n",
    "\n",
    "args_cpmnn = parse_train_args()\n",
    "modify_train_args(args_cpmnn)\n",
    "\n",
    "args_cpmnn.emb_dim = 300\n",
    "\n",
    "args_cpmnn.dataset_type = 'classification'\n",
    "args_cpmnn.metric = 'auc'\n",
    "\n",
    "args_cpmnn.data_path = 'data/S_dataset_modify.csv'\n",
    "\n",
    "debug = print\n",
    "logger = None\n",
    "\n",
    "debug('Loading data')\n",
    "args_cpmnn.task_names = get_task_names(args_cpmnn.data_path)\n",
    "data = get_data(path=args_cpmnn.data_path, args=args_cpmnn, logger=logger)\n",
    "args_cpmnn.num_tasks = data.num_tasks()\n",
    "args_cpmnn.features_size = data.features_size()\n",
    "debug(f'Number of tasks = {args_cpmnn.num_tasks}')\n",
    "\n",
    "cpmnn = build_model(args_cpmnn)\n",
    "cpmnn.to(device);\n",
    "\n",
    "discriminator = Discriminator(args.emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Infomax(cpmnn, discriminator)\n",
    "model.to(device)\n",
    "\n",
    "#set up optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(args, model, device, loader, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    train_acc_accum = 0\n",
    "    train_loss_accum = 0\n",
    "\n",
    "    for step, batch in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        _, node_emb = model.gnn.encoder(batch.smile)\n",
    "        node_emb = node_emb.narrow(0, 0, len(batch.batch))\n",
    "        summary_emb = torch.sigmoid(model.pool(node_emb, batch.batch))\n",
    "\n",
    "        positive_expanded_summary_emb = summary_emb[batch.batch]\n",
    "\n",
    "        shifted_summary_emb = summary_emb[cycle_index(len(summary_emb), 1)]\n",
    "        negative_expanded_summary_emb = shifted_summary_emb[batch.batch]\n",
    "\n",
    "        positive_score = model.discriminator(node_emb, positive_expanded_summary_emb)\n",
    "        negative_score = model.discriminator(node_emb, negative_expanded_summary_emb)      \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(positive_score, torch.ones_like(positive_score)) + model.loss(negative_score, torch.zeros_like(negative_score))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_accum += float(loss.detach().cpu().item())\n",
    "        acc = (torch.sum(positive_score > 0) + torch.sum(negative_score < 0)).to(torch.float32)/float(2*len(positive_score))\n",
    "        train_acc_accum += float(acc.detach().cpu().item())\n",
    "\n",
    "    return train_acc_accum/step, train_loss_accum/step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 ('GVQA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02661a34c3c16c5a67f1a990a3a8e1e6dde091cad135f4d415764b2394fb826e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}